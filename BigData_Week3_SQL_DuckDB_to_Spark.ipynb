{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fecde574",
   "metadata": {},
   "source": [
    "# Big Data : SQL Analytics ‡∏î‡πâ‡∏ß‡∏¢ DuckDB ‚Üí Spark SQL\n",
    "\n",
    "> ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ: ‡πÉ‡∏ä‡πâ **SQL** ‡πÄ‡∏û‡∏∑‡πà‡∏≠ ‚Äú‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‚Äù ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà (CSV/Parquet) ‡∏î‡πâ‡∏ß‡∏¢ **DuckDB** ‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î performance ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡πÉ‡∏ä‡πâ **Spark SQL** ‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ\n",
    "\n",
    "**‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á**: Google Colab (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥) / Local Jupyter  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7078e8",
   "metadata": {},
   "source": [
    "##  ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å Bash Commands ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\n",
    "\n",
    "![Bash Terminal](images/bash_cmd.png)\n",
    "\n",
    "\n",
    "### ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ Command Line?\n",
    "\n",
    "‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏Ç‡∏≠‡∏á Data Engineering ‡πÅ‡∏•‡∏∞ Big Data ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö:\n",
    "- **Remote Servers** (‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô Cloud ‡πÄ‡∏ä‡πà‡∏ô AWS EC2, Google Cloud)\n",
    "- **Data Lakes** (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡∏ö‡∏ô S3, HDFS)\n",
    "- **Cluster Computing** (Spark Cluster ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á)\n",
    "\n",
    "‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤**‡πÑ‡∏°‡πà‡∏°‡∏µ GUI** (Graphical User Interface) ‡πÉ‡∏´‡πâ‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ö‡∏ô Windows/Mac\n",
    "‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ **Command Line Interface (CLI)** ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ **Terminal/Bash** ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô\n",
    "\n",
    "### ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Ç‡∏≠‡∏á Bash Commands:\n",
    "1. **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Å‡πà‡∏≠‡∏ô‡πÇ‡∏´‡∏•‡∏î**: ‡∏î‡∏π‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà ‡∏°‡∏µ‡∏Å‡∏µ‡πà‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£\n",
    "2. **‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤**: ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠ Download ‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏°‡∏≤‡∏î‡∏π‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á\n",
    "3. **Automation**: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Script ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ã‡πâ‡∏≥ ‡πÜ ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\n",
    "4. **‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö Big Data**: ‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏ô‡∏≤‡∏î GB-TB ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏î‡πâ‡∏ß‡∏¢ Excel ‡πÑ‡∏î‡πâ\n",
    "\n",
    "### ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ:\n",
    "\n",
    "#### 1. `pwd` (Print Working Directory)\n",
    "- **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢**: ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏≠‡∏¢‡∏π‡πà\n",
    "- **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**: `/home/username/data`\n",
    "- **‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà‡πÉ‡∏ä‡πâ**: ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏á‡∏ó‡∏≤‡∏á‡∏ß‡πà‡∏≤‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÑ‡∏´‡∏ô\n",
    "\n",
    "#### 2. `ls` (List)\n",
    "- **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢**: ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÉ‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\n",
    "- **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**: `ls` ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå\n",
    "- **Options ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢**:\n",
    "  - `ls -l` ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î (‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå, ‡∏Ç‡∏ô‡∏≤‡∏î, ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà)\n",
    "  - `ls -lh` ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ (MB, GB ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô bytes)\n",
    "  - `ls -a` ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ã‡πà‡∏≠‡∏ô‡∏≠‡∏¢‡∏π‡πà (‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ `.`)\n",
    "\n",
    "#### 3. `cd` (Change Directory)\n",
    "- **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢**: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå\n",
    "- **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**:\n",
    "  - `cd data` ‚Üí ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data\n",
    "  - `cd ..` ‚Üí ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤\n",
    "  - `cd ~` ‚Üí ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏µ‡πà Home directory\n",
    "\n",
    "#### 4. `head` (‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å)\n",
    "- **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢**: ‡πÅ‡∏™‡∏î‡∏á 10 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå (Default)\n",
    "- **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**:\n",
    "  - `head sample_data/california_housing_train.csv` ‚Üí ‡∏î‡∏π 10 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å\n",
    "  - `head -n 5 sample_data/california_housing_train.csv` ‚Üí ‡∏î‡∏π 5 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å\n",
    "- **‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà‡πÉ‡∏ä‡πâ**: ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏π‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ Header ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£\n",
    "\n",
    "#### 5. `tail` (‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡πâ‡∏≤‡∏¢)\n",
    "- **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢**: ‡πÅ‡∏™‡∏î‡∏á 10 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå\n",
    "- **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**: `tail -n 20 sample_data/california_housing_train.csv` ‚Üí ‡∏î‡∏π 20 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢\n",
    "- **‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà‡πÉ‡∏ä‡πâ**: ‡∏î‡∏π‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏π Log ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î\n",
    "\n",
    "#### 6. `cat` (Concatenate)\n",
    "- **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢**: ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå\n",
    "- **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**: `cat small_file.txt`\n",
    "- **‚ö†Ô∏è ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô**: ‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà! ‡∏à‡∏≠‡∏à‡∏∞‡∏ó‡πà‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏à‡∏Ñ‡πâ‡∏≤‡∏á\n",
    "\n",
    "#### 7. `wc` (Word Count)\n",
    "- **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢**: ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î, ‡∏Ñ‡∏≥, bytes\n",
    "- **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**:\n",
    "  - `wc -l sample_data/california_housing_train.csv` ‚Üí ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î (‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏µ‡πà‡πÅ‡∏ñ‡∏ß)\n",
    "  - `wc -c sample_data/california_housing_train.csv` ‚Üí ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô bytes (‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå)\n",
    "\n",
    "#### 8. `grep` (‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)\n",
    "- **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢**: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏\n",
    "- **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**: `grep \"THEFT\" sample_data/california_housing_train.csv` ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ THEFT\n",
    "\n",
    "### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô Jupyter/Colab\n",
    "\n",
    "‡πÉ‡∏ô Jupyter Notebook ‡∏´‡∏£‡∏∑‡∏≠ Google Colab ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á Bash ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÄ‡∏ï‡∏¥‡∏° `!` ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤:\n",
    "\n",
    "```python\n",
    "!pwd                    # ‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÑ‡∏´‡∏ô\n",
    "!ls -lh                 # ‡∏î‡∏π‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå\n",
    "!head -n 5 sample_data/california_housing_train.csv    # ‡∏î‡∏π 5 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å\n",
    "!wc -l sample_data/california_housing_train.csv        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î\n",
    "```\n",
    "\n",
    "### ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡πá‡∏Ñ‡∏Å‡πà‡∏≠‡∏ô‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•?\n",
    "\n",
    "**‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏à‡∏£‡∏¥‡∏á**:\n",
    "1. ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏à‡∏≠‡πÑ‡∏ü‡∏•‡πå `sales_data.csv` ‡∏ö‡∏ô S3\n",
    "2. ‡∏ñ‡πâ‡∏≤ Download ‡∏°‡∏≤‡πÄ‡∏•‡∏¢ ‡∏≠‡∏≤‡∏à‡∏û‡∏ö‡∏ß‡πà‡∏≤:\n",
    "   - ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà 50 GB (‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ Download ‡∏ô‡∏≤‡∏ô)\n",
    "   - ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢ (‡∏°‡∏µ‡πÅ‡∏ï‡πà Header ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)\n",
    "   - Format ‡∏ú‡∏¥‡∏î (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ `;` ‡πÅ‡∏ó‡∏ô `,`)\n",
    "3. ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ `head` ‡∏î‡∏π‡∏Å‡πà‡∏≠‡∏ô ‡∏à‡∏∞‡∏£‡∏π‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "\n",
    "> **üí° Best Practice**: ‡∏Å‡πà‡∏≠‡∏ô Load ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ Python/SQL ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ Bash ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏™‡∏°‡∏≠!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ff9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Bash Commands ‡πÉ‡∏ô Jupyter/Colab\n",
    "# (‡∏•‡∏ö # ‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô)\n",
    "\n",
    "# !pwd                    # ‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÑ‡∏´‡∏ô\n",
    "# !ls -lh                 # ‡∏î‡∏π‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡∏ô‡∏≤‡∏î\n",
    "# !head -n 5 sample_data/california_housing_train.csv    # ‡∏î‡∏π 5 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå\n",
    "# !wc -l sample_data/california_housing_train.csv        # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "# !grep 100 sample_data/california_housing_train.csv | head -n 3  # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ THEFT ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á 3 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4facdf",
   "metadata": {},
   "source": [
    "## 0.1) History & Importance of SQL\n",
    "\n",
    "![SQL Timeline](images/sql_timeline.png)\n",
    "\n",
    "![SQL Evolution](images/sql_evolution.png)\n",
    "\n",
    "\n",
    "### ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏¢‡πà‡∏≠‡∏Ç‡∏≠‡∏á SQL (Structured Query Language)\n",
    "\n",
    "SQL ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå (Relational Database) ‡∏°‡∏≤‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏¢‡∏∏‡∏Ñ 1970 ‡πÅ‡∏•‡∏∞‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\n",
    "\n",
    "#### Timeline ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:\n",
    "- **1970**: Edgar Codd ‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏à‡∏≤‡∏Å IBM ‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏° *\"A Relational Model of Data for Large Shared Data Banks\"* ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á Relational Database\n",
    "- **1974-1975**: IBM ‡∏û‡∏±‡∏í‡∏ô‡∏≤ SEQUEL (Structured English Query Language) ‡∏ã‡∏∂‡πà‡∏á‡∏ï‡πà‡∏≠‡∏°‡∏≤‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô SQL ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö System R\n",
    "- **1979**: Oracle Corporation (‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏¥‡∏° Relational Software Inc.) ‡πÄ‡∏õ‡∏¥‡∏î‡∏ï‡∏±‡∏ß Oracle V2 ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô RDBMS ‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏≤‡∏ì‡∏¥‡∏ä‡∏¢‡πå‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡πÇ‡∏•‡∏Å\n",
    "- **1986**: ANSI (American National Standards Institute) ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡πÉ‡∏´‡πâ SQL ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£\n",
    "- **1987**: ISO (International Organization for Standardization) ‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á SQL ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏™‡∏≤‡∏Å‡∏•\n",
    "- **‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô**: SQL ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô RDBMS ‡πÅ‡∏ö‡∏ö‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°, Data Warehouse, ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏°‡πâ‡πÅ‡∏ï‡πà‡∏£‡∏∞‡∏ö‡∏ö Big Data\n",
    "\n",
    "### ‡∏ß‡∏¥‡∏ß‡∏±‡∏í‡∏ô‡∏≤‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á SQL Engine\n",
    "\n",
    "SQL ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á **‡∏†‡∏≤‡∏©‡∏≤** (Language) ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á ‡πÅ‡∏ï‡πà‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏Ñ‡∏∑‡∏≠ **Engine** ‡∏´‡∏£‡∏∑‡∏≠ **Database Management System (DBMS)** ‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏µ‡∏ß‡∏¥‡∏ß‡∏±‡∏í‡∏ô‡∏≤‡∏Å‡∏≤‡∏£‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏¢‡∏∏‡∏Ñ‡∏™‡∏°‡∏±‡∏¢:\n",
    "\n",
    "#### 1. RDBMS (Row-oriented) - ‡∏¢‡∏∏‡∏Ñ‡πÅ‡∏£‡∏Å\n",
    "- **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**: Oracle, PostgreSQL, MySQL, SQL Server\n",
    "- **‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô**: ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô **OLTP (Online Transaction Processing)** ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏∞‡∏ö‡∏ö‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£, ‡∏£‡∏∞‡∏ö‡∏ö E-commerce\n",
    "- **‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö**: ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô **‡πÅ‡∏ñ‡∏ß** (Row) ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£ Insert/Update/Delete ‡πÄ‡∏£‡πá‡∏ß\n",
    "- **‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î**: ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà (Analytical Query) ‡∏ä‡πâ‡∏≤ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡πÅ‡∏ñ‡∏ß‡πÅ‡∏°‡πâ‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡πà‡∏ö‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\n",
    "\n",
    "#### 2. Data Warehouse (Column-oriented) - ‡∏¢‡∏∏‡∏Ñ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå\n",
    "- **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**: Teradata, Netezza, Vertica, Amazon Redshift\n",
    "- **‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô**: ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏á‡∏≤‡∏ô **OLAP (Online Analytical Processing)** ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢, ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°\n",
    "- **‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö**: ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô **‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå** (Column) ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å\n",
    "- **‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Compression ‡πÑ‡∏î‡πâ‡∏î‡∏µ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏°‡∏±‡∏Å‡∏°‡∏µ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô\n",
    "\n",
    "#### 3. Big Data Era (Distributed) - ‡∏¢‡∏∏‡∏Ñ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà\n",
    "- **Apache Hive**: ‡πÅ‡∏õ‡∏•‡∏á SQL ‡πÄ‡∏õ‡πá‡∏ô MapReduce jobs ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ö‡∏ô Hadoop (‡∏ä‡πâ‡∏≤ ‡πÅ‡∏ï‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î Petabyte)\n",
    "- **Spark SQL**: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö In-Memory (‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÅ‡∏£‡∏°) ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ Hive ‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏ó‡πà‡∏≤ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Batch ‡πÅ‡∏•‡∏∞ Streaming\n",
    "- **Presto/Trino**: Interactive Query Engine ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ Query ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏´‡∏•‡πà‡∏á (S3, MySQL, Postgres) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ\n",
    "- **‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô**: ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÑ‡∏õ‡∏ó‡∏≥‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢‡∏£‡πâ‡∏≠‡∏¢-‡∏´‡∏•‡∏≤‡∏¢‡∏û‡∏±‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (Distributed Computing)\n",
    "\n",
    "#### 4. Modern In-Process Analytics - ‡∏¢‡∏∏‡∏Ñ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\n",
    "- **DuckDB**: ‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• OLAP ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (In-Process) ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô SQLite ‡πÅ‡∏ï‡πà‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå\n",
    "- **‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô**: ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Server, ‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å, ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö Data Scientist ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ö‡∏ô Laptop\n",
    "- **‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î**: ‡∏ñ‡∏π‡∏Å‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏î‡πâ‡∏ß‡∏¢ RAM ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• TB-PB)\n",
    "\n",
    "### ‡∏ó‡∏≥‡πÑ‡∏° SQL ‡∏ñ‡∏∂‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö Data Engineer/Scientist?\n",
    "\n",
    "#### 1. Universal Interface (‡∏†‡∏≤‡∏©‡∏≤‡∏™‡∏≤‡∏Å‡∏•)\n",
    "- ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô CSV, Parquet, PostgreSQL, MySQL, S3 Data Lake ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏°‡πâ‡πÅ‡∏ï‡πà Google Sheets\n",
    "- ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ SQL ‡πÄ‡∏û‡∏∑‡πà‡∏≠ Query ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "- **‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**: DuckDB ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ Query ‡πÑ‡∏ü‡∏•‡πå Parquet ‡∏ö‡∏ô S3 ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Download\n",
    "\n",
    "#### 2. Declarative Programming (‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£)\n",
    "- ‡πÄ‡∏£‡∏≤‡πÅ‡∏Ñ‡πà‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ß‡πà‡∏≤ `SELECT name, SUM(sales) FROM orders WHERE year = 2023 GROUP BY name`\n",
    "- Engine ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ô‡∏´‡∏≤‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Query Optimization) ‡πÄ‡∏ä‡πà‡∏ô:\n",
    "  - ‡πÉ‡∏ä‡πâ Index ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ\n",
    "  - ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Partition ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "  - ‡∏ó‡∏≥ Parallel Processing\n",
    "- ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô Python Loop ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏¥‡∏î‡πÄ‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á ‡πÅ‡∏•‡∏∞‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤\n",
    "\n",
    "#### 3. Scalability (‡∏Ç‡∏¢‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)\n",
    "- SQL ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ô‡∏ö‡∏ô:\n",
    "  - SQLite (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• MB-GB ‡∏ö‡∏ô‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠)\n",
    "  - PostgreSQL (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• GB-TB ‡∏ö‡∏ô Server)\n",
    "  - Spark SQL (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• TB-PB ‡∏ö‡∏ô Cluster)\n",
    "- ‡πÄ‡∏£‡∏≤‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡πÉ‡∏´‡∏°‡πà ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏Ñ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Engine\n",
    "\n",
    "#### 4. Industry Standard (‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°)\n",
    "- ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡πÉ‡∏ô‡∏ó‡∏µ‡∏° Data (Analyst, Engineer, Scientist) ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å SQL\n",
    "- ‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£ Collaborate ‡πÅ‡∏•‡∏∞ Maintain ‡πÇ‡∏Ñ‡πâ‡∏î\n",
    "- ‡∏°‡∏µ Community ‡πÅ‡∏•‡∏∞ Resources ‡∏°‡∏≤‡∏Å‡∏°‡∏≤‡∏¢\n",
    "\n",
    "![SQL Engine Types](images/sql_engine_types.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c05628",
   "metadata": {},
   "source": [
    "## 0) Setup & ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á DuckDB (Colab)\n",
    "\n",
    "> ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô Colab ‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô cell ‡∏ô‡∏µ‡πâ‡∏Å‡πà‡∏≠‡∏ô\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df6c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á (Colab)\n",
    "!pip -q install duckdb pandas pyarrow\n",
    "\n",
    "import duckdb, pandas as pd, time, os\n",
    "print(\"DuckDB version:\", duckdb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eccd7e",
   "metadata": {},
   "source": [
    "## 1) ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "\n",
    "- ‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö notebook ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏£‡∏á ‡πÜ\n",
    "- ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏ô‡∏•‡∏∞‡∏ó‡∏µ‡πà ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà path ‡πÄ‡∏ï‡πá‡∏°\n",
    "\n",
    "> **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏**: ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á/Colab ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡∏™‡∏≠‡∏ô‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î ‡∏´‡∏£‡∏∑‡∏≠ mount Drive ‡∏Å‡πà‡∏≠‡∏ô\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ad624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÉ‡∏ä‡πâ Dataset California Housing ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ô Colab\n",
    "CSV_PATH = \"sample_data/california_housing_train.csv\"\n",
    "PARQUET_PATH = \"housing.parquet\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Parquet ‡∏à‡∏≤‡∏Å CSV ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö Performance (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ)\n",
    "if not os.path.exists(PARQUET_PATH) and os.path.exists(CSV_PATH):\n",
    "    print(f\"üî® ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á {PARQUET_PATH} ‡∏à‡∏≤‡∏Å CSV...\")\n",
    "    pd.read_csv(CSV_PATH).to_parquet(PARQUET_PATH)\n",
    "    print(\"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Parquet ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô\")\n",
    "\n",
    "print(\"CSV exists:\", os.path.exists(CSV_PATH))\n",
    "print(\"Parquet exists:\", os.path.exists(PARQUET_PATH))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bacde",
   "metadata": {},
   "source": [
    "## 2) ‡∏™‡∏£‡πâ‡∏≤‡∏á Connection + ‡∏™‡∏£‡πâ‡∏≤‡∏á VIEW\n",
    "\n",
    "‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î:\n",
    "- ‡πÄ‡∏£‡∏≤‡∏à‡∏∞ query ‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á import ‡πÄ‡∏Ç‡πâ‡∏≤ DB)\n",
    "- ‡∏™‡∏£‡πâ‡∏≤‡∏á `VIEW` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô SQL ‡∏™‡∏±‡πâ‡∏ô‡∏•‡∏á\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e39ef6d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()\n",
    "\n",
    "\n",
    "\n",
    "# Parquet view\n",
    "if os.path.exists(PARQUET_PATH):\n",
    "    con.execute(f\"\"\"\n",
    "        CREATE OR REPLACE VIEW crime_parquet AS\n",
    "        SELECT * FROM read_parquet('{PARQUET_PATH}');\n",
    "    \"\"\")\n",
    "    print(\"‚úÖ created view: crime_parquet\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå PARQUET_PATH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea9099",
   "metadata": {},
   "source": [
    "## 3) ‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ (LIMIT)\n",
    "\n",
    "> **‡∏´‡πâ‡∏≤‡∏°** `SELECT *` ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà `LIMIT` ‡πÄ‡∏ß‡∏•‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏ç‡πà\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å view ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á (parquet ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‡∏à‡∏∞ prefer ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏£‡πá‡∏ß)\n",
    "available = [v[0] for v in con.execute(\"SHOW TABLES\").fetchall()]\n",
    "table = \"housing_parquet\" if \"housing_parquet\" in available else (\"housing_csv\" if \"housing_csv\" in available else None)\n",
    "\n",
    "assert table is not None, \"‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ housing data ‡∏´‡∏£‡∏∑‡∏≠ crime.parquet\"\n",
    "\n",
    "con.execute(f\"SELECT * FROM {table} LIMIT 10\").df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d6baba",
   "metadata": {},
   "source": [
    "## 4) ‡∏ï‡∏£‡∏ß‡∏à schema / ‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "\n",
    "> ‡∏ñ‡πâ‡∏≤ type ‡∏ú‡∏¥‡∏î (‡πÄ‡∏ä‡πà‡∏ô year ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°) ‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ sort/‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ú‡∏¥‡∏î‡πÑ‡∏î‡πâ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(f\"DESCRIBE SELECT * FROM {table}\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d04cf",
   "metadata": {},
   "source": [
    "### SQL Logical Order of Execution (‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á)\n",
    "\n",
    "‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà Database Engine ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡∏ã‡∏∂‡πà‡∏á‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô (Lexical Order)\n",
    "\n",
    "![SQL Logical Order](images/sql_logical_order_v2.png)\n",
    "\n",
    "> **Note**: ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏ß‡πà‡∏≤ `SELECT` ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢! ‡∏ô‡∏±‡πà‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡πÑ‡∏°‡πÄ‡∏£‡∏≤‡∏ñ‡∏∂‡∏á‡πÉ‡∏ä‡πâ Alias (‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏•‡πà‡∏ô) ‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡πÉ‡∏ô SELECT ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô WHERE ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18191dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏•‡∏≠‡∏á‡∏£‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á ‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô SQL\n",
    "con.execute(f\"\"\"\n",
    "    SELECT median_house_value, housing_median_age, total_rooms\n",
    "    FROM {table}\n",
    "    WHERE housing_median_age > 50\n",
    "    LIMIT 20\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2f4892",
   "metadata": {},
   "source": [
    "### ‚úÖ ‡πÇ‡∏à‡∏ó‡∏¢‡πå 1 (Easy)\n",
    "1) ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á  \n",
    "2) ‡πÅ‡∏™‡∏î‡∏á 5 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 3‚Äì5 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏û‡∏≠)\n",
    "\n",
    "‡πÄ‡∏ï‡∏¥‡∏° SQL ‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba0a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ‡πÄ‡∏ï‡∏¥‡∏° SQL ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö\n",
    "sql1 = f\"\"\"\n",
    "SELECT ________ AS n_rows\n",
    "FROM {table}\n",
    "\"\"\"\n",
    "\n",
    "# sql2: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 3-5 ‡∏ï‡∏±‡∏ß + LIMIT 5\n",
    "sql2 = f\"\"\"\n",
    "SELECT ________, ________, ________\n",
    "FROM {table}\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "# ‡∏£‡∏±‡∏ô\n",
    "try:\n",
    "    print(con.execute(sql1).df())\n",
    "    display(con.execute(sql2).df())\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a839f991",
   "metadata": {},
   "source": [
    "## 6) Aggregation: GROUP BY / ORDER BY\n",
    "\n",
    "‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î: Big Data ‡πÑ‡∏°‡πà‡∏î‡∏π‡∏ó‡∏µ‡∏•‡∏∞‡πÅ‡∏ñ‡∏ß ‚Üí ‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b0749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(f\"\"\"\n",
    "    SELECT\n",
    "      housing_median_age,\n",
    "      COUNT(*) AS total_houses,\n",
    "      AVG(median_house_value) AS avg_price\n",
    "    FROM {table}\n",
    "    GROUP BY housing_median_age\n",
    "    ORDER BY total_houses DESC\n",
    "    LIMIT 10\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dde817e",
   "metadata": {},
   "source": [
    "### ‚úÖ ‡πÇ‡∏à‡∏ó‡∏¢‡πå 2 (Medium)\n",
    "1) ‡∏´‡∏≤ **district** ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏‡πÄ‡∏¢‡∏≠‡∏∞‡∏™‡∏∏‡∏î 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö  \n",
    "2) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö district ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 1: ‡∏´‡∏≤ **crime_type** ‡∏ó‡∏µ‡πà‡πÄ‡∏¢‡∏≠‡∏∞‡∏™‡∏∏‡∏î 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö  \n",
    "\n",
    "‡∏ó‡∏≥‡πÄ‡∏õ‡πá‡∏ô 2 query (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á subquery)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ‡πÄ‡∏ï‡∏¥‡∏° SQL\n",
    "sql_top_age = f\"\"\"\n",
    "SELECT housing_median_age, COUNT(*) AS total_houses\n",
    "FROM {table}\n",
    "GROUP BY housing_median_age\n",
    "ORDER BY total_houses DESC\n",
    "LIMIT 5\n",
    "\"\"\".strip()\n",
    "\n",
    "sql_price_by_age = f\"\"\"\n",
    "-- ‡πÅ‡∏Å‡πâ‡∏Ñ‡πà‡∏≤ 52 (‡∏≠‡∏≤‡∏¢‡∏∏‡∏ö‡πâ‡∏≤‡∏ô) ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏¢‡∏≤‡∏Å‡∏£‡∏π‡πâ\n",
    "SELECT housing_median_age, AVG(median_house_value) AS avg_price\n",
    "FROM {table}\n",
    "WHERE housing_median_age = 52\n",
    "GROUP BY housing_median_age\n",
    "\"\"\".strip()\n",
    "\n",
    "try:\n",
    "    display(con.execute(sql_top_age).df())\n",
    "    display(con.execute(sql_price_by_age).df())\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adcba4e",
   "metadata": {},
   "source": [
    "## 7) Performance Lab: CSV vs Parquet + Timing\n",
    "\n",
    "‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ß‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤ query ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏ö‡∏ô CSV ‡πÅ‡∏•‡∏∞ Parquet (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bccdd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_query(sql: str, repeat: int = 3) -> float:\n",
    "    times = []\n",
    "    for _ in range(repeat):\n",
    "        t0 = time.time()\n",
    "        con.execute(sql).fetchall()\n",
    "        times.append(time.time() - t0)\n",
    "    return min(times)\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á query ‡∏ó‡∏µ‡πà‡∏°‡∏±‡∏Å‡πÑ‡∏î‡πâ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏à‡∏≤‡∏Å Parquet (filter + count)\n",
    "q = \"\"\"SELECT COUNT(*) FROM {table} WHERE housing_median_age > 10 AND median_house_value > 100000\"\"\".format(table=table)\n",
    "print(\"table:\", table)\n",
    "print(\"query:\", q)\n",
    "print(\"time (best of 3):\", time_query(q), \"sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c91193d",
   "metadata": {},
   "source": [
    "### ‚úÖ ‡πÇ‡∏à‡∏ó‡∏¢‡πå 3 (Analysis)\n",
    "1) ‡∏•‡∏≠‡∏á query ‡πÅ‡∏ö‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ô‡πâ‡∏≠‡∏¢ (‡πÄ‡∏ä‡πà‡∏ô COUNT ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 1 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå)  \n",
    "2) ‡∏•‡∏≠‡∏á query ‡πÅ‡∏ö‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏¢‡∏≠‡∏∞ (‡πÄ‡∏ä‡πà‡∏ô SELECT 6‚Äì10 ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå)  \n",
    "3) ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ß‡∏•‡∏≤ ‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡πÜ: **‡∏ó‡∏≥‡πÑ‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏≤‡∏à‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏•‡∏≠‡∏á‡∏£‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á ‡πÉ‡∏´‡πâ‡πÅ‡∏Å‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô SQL\n",
    "con.execute(f\"\"\"\n",
    "    SELECT median_house_value, housing_median_age, total_rooms\n",
    "    FROM {table}\n",
    "    WHERE housing_median_age > 50\n",
    "    LIMIT 20\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d89483",
   "metadata": {},
   "source": [
    "## 8) EXPLAIN / EXPLAIN ANALYZE (‡∏î‡∏π execution plan)\n",
    "\n",
    "> ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞ scan/ filter/ aggregate ‡∏¢‡∏±‡∏á‡πÑ‡∏á\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(f\"\"\"\n",
    "EXPLAIN SELECT COUNT(*)\n",
    "FROM {table}\n",
    "WHERE housing_median_age > 20\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ad6119",
   "metadata": {},
   "source": [
    "## 9) JOIN + CTE\n",
    "\n",
    "‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á lookup ‡πÄ‡∏•‡πá‡∏Å ‡πÜ (dimension) ‡πÅ‡∏•‡πâ‡∏ß JOIN\n",
    "\n",
    "![SQL Join CTE](images/sql_join_cte.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b18f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_map = pd.DataFrame({\n",
    "    \"housing_median_age\": range(1, 100),\n",
    "    \"category\": [\"New\" if x < 20 else (\"Mid\" if x < 40 else \"Old\") for x in range(1, 100)]\n",
    "})\n",
    "con.register(\"age_map\", age_map)\n",
    "\n",
    "con.execute(\"SELECT * FROM age_map LIMIT 5\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a35a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(f\"\"\"\n",
    "    SELECT\n",
    "      m.category,\n",
    "      COUNT(*) AS total_houses,\n",
    "      AVG(h.median_house_value) AS avg_price\n",
    "    FROM {table} h\n",
    "    JOIN age_map m\n",
    "      ON h.housing_median_age = m.housing_median_age\n",
    "    GROUP BY m.category\n",
    "    ORDER BY avg_price DESC\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb4c2e9",
   "metadata": {},
   "source": [
    "### ‚úÖ ‡πÇ‡∏à‡∏ó‡∏¢‡πå 4 (Medium‚ÄìHard): CTE 2 ‡∏ä‡∏±‡πâ‡∏ô\n",
    "- `base`: ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏õ‡∏µ 2023  \n",
    "- `agg`: ‡∏£‡∏ß‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡πà‡∏≠ district  \n",
    "- ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Top 5 district\n",
    "\n",
    "‡πÄ‡∏ï‡∏¥‡∏° SQL ‡πÉ‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f426a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_cte = f\"\"\"\n",
    "WITH base AS (\n",
    "  SELECT housing_median_age\n",
    "  FROM {table}\n",
    "  WHERE median_house_value > 200000\n",
    "),\n",
    "agg AS (\n",
    "  SELECT housing_median_age, COUNT(*) AS total_cases\n",
    "  FROM base\n",
    "  GROUP BY housing_median_age\n",
    ")\n",
    "SELECT *\n",
    "FROM agg\n",
    "ORDER BY total_cases DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "con.execute(sql_cte).df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc099f2",
   "metadata": {},
   "source": [
    "## 10) Window Functions: TOP-N ‡∏ï‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏°\n",
    "\n",
    "‡πÉ‡∏ä‡πâ `ROW_NUMBER()` ‡∏´‡∏£‡∏∑‡∏≠ `DENSE_RANK()` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤ Top crime_type ‡∏ï‡πà‡∏≠ district\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20503787",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_window = f\"\"\"\n",
    "WITH ranked AS (\n",
    "  SELECT\n",
    "    housing_median_age,\n",
    "    median_house_value,\n",
    "    ROW_NUMBER() OVER (PARTITION BY housing_median_age ORDER BY median_house_value DESC) AS rn\n",
    "  FROM {table}\n",
    ")\n",
    "SELECT housing_median_age, median_house_value\n",
    "FROM ranked\n",
    "WHERE rn <= 3\n",
    "ORDER BY housing_median_age, median_house_value DESC\n",
    "LIMIT 10;\n",
    "\"\"\".strip()\n",
    "\n",
    "con.execute(sql_window).df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768c5230",
   "metadata": {},
   "source": [
    "### ‚úÖ ‡πÇ‡∏à‡∏ó‡∏¢‡πå 5 (Hard): ROW_NUMBER vs DENSE_RANK\n",
    "1) ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô `ROW_NUMBER()` ‡πÄ‡∏õ‡πá‡∏ô `DENSE_RANK()`  \n",
    "2) ‡∏î‡∏π‡∏ú‡∏•‡∏ï‡πà‡∏≤‡∏á (‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô)  \n",
    "3) ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡πÜ 2‚Äì3 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î: ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a369c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô DENSE_RANK\n",
    "sql_dense = f\"\"\"\n",
    "WITH ranked AS (\n",
    "  SELECT\n",
    "    housing_median_age,\n",
    "    median_house_value,\n",
    "    DENSE_RANK() OVER (PARTITION BY housing_median_age ORDER BY median_house_value DESC) AS rk\n",
    "  FROM {table}\n",
    ")\n",
    "SELECT housing_median_age, median_house_value, rk\n",
    "FROM ranked\n",
    "WHERE rk <= 3\n",
    "ORDER BY housing_median_age, median_house_value DESC\n",
    "LIMIT 10;\n",
    "\"\"\".strip()\n",
    "\n",
    "con.execute(sql_dense).df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a8902",
   "metadata": {},
   "source": [
    "## 11) ‡πÇ‡∏¢‡∏á‡πÑ‡∏õ Spark SQL (Concept Bridge)\n",
    "\n",
    "‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ DuckDB ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏ï‡πà SQL ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô ‚Äú‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‚Äù ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ Spark SQL ‡πÑ‡∏î‡πâ\n",
    "\n",
    "### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô\n",
    "- `SELECT/WHERE/GROUP BY/JOIN/CTE/WINDOW`\n",
    "\n",
    "### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô Spark\n",
    "- Distributed execution, partition, shuffle\n",
    "- Lazy evaluation\n",
    "- Physical plan + tuning (memory, spill, skew)\n",
    "\n",
    "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3bd68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î (‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏ô‡πÉ‡∏ô‡∏Ñ‡∏≤‡∏ö‡∏ô‡∏µ‡πâ)\n",
    "# df = spark.read.parquet(\"crime.parquet\")\n",
    "# df.createOrReplaceTempView(\"crime\")\n",
    "#\n",
    "# spark.sql(\"\"\"\n",
    "#   SELECT district, COUNT(*) AS total\n",
    "#   FROM crime\n",
    "#   WHERE year = 2023\n",
    "#   GROUP BY district\n",
    "#   ORDER BY total DESC\n",
    "#   LIMIT 10\n",
    "# \"\"\").show()\n",
    "\n",
    "print(\"‚úÖ ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏ö‡∏ó‡∏µ‡πà DuckDB + SQL\n",
    "‡∏Ñ‡∏≤‡∏ö‡∏ñ‡∏±‡∏î‡πÑ‡∏õ: Spark Architecture + Spark SQL ‡∏ö‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô/‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33dd5ff",
   "metadata": {},
   "source": [
    "## 12) Checklist ‡∏™‡πà‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏Ñ‡∏≤‡∏ö\n",
    "\n",
    "- [ ] ‡πÉ‡∏ä‡πâ LIMIT ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà preview\n",
    "- [ ] ‡∏ó‡∏≥‡πÇ‡∏à‡∏ó‡∏¢‡πå 1‚Äì5 ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 3 ‡∏Ç‡πâ‡∏≠\n",
    "- [ ] ‡∏£‡∏±‡∏ô EXPLAIN ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏Ñ‡∏õ‡∏ú‡∏• 1 ‡∏£‡∏π‡∏õ\n",
    "- [ ] ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô reflection 5‚Äì8 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î: Parquet ‡∏ä‡πà‡∏ß‡∏¢‡∏¢‡∏±‡∏á‡πÑ‡∏á? SQL ‡∏ä‡πà‡∏ß‡∏¢‡∏¢‡∏±‡∏á‡πÑ‡∏á?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195e91ae",
   "metadata": {},
   "source": [
    "# 12) Database Optimization & Performance Tricks (‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û Query)\n",
    "\n",
    "‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô SQL ‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÑ‡∏°‡πà‡∏û‡∏≠ ‡πÉ‡∏ô‡πÇ‡∏•‡∏Å Big Data ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÉ‡∏´‡πâ **‡πÄ‡∏£‡πá‡∏ß** ‡πÅ‡∏•‡∏∞ **‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£** ‡∏î‡πâ‡∏ß‡∏¢\n",
    "\n",
    "### ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô\n",
    "1. **Select Only What You Need**: ‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏ä‡πâ `SELECT *` ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ô Parquet/Columnar DB) ‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏ß‡∏•‡∏≤‡∏°‡∏≤‡∏Å\n",
    "2. **Filter Early**: ‡πÉ‡∏ä‡πâ `WHERE` ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô rows ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ô‡∏≥‡πÑ‡∏õ JOIN ‡∏´‡∏£‡∏∑‡∏≠ Aggregate\n",
    "3. **Understanding Storage**: ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á Row vs Column Store (‡∏ï‡∏≤‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô)\n",
    "\n",
    "### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß\n",
    "‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ó‡∏î‡∏•‡∏≠‡∏á Query ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà \"‡πÑ‡∏°‡πà‡∏î‡∏µ\" (Full Scan) ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà \"‡∏î‡∏µ\" (Predicate Pushdown + Column Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 1. Bad Query: SELECT * ‡πÅ‡∏•‡∏∞ Filter ‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á (‡∏à‡∏≥‡∏•‡∏≠‡∏á)\n",
    "def run_bad_query():\n",
    "    start = time.time()\n",
    "    # ‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡∏°‡∏≤ filter ‡πÉ‡∏ô Python Application (‡∏™‡∏°‡∏°‡∏ï‡∏¥)\n",
    "    df = con.execute(\"SELECT * FROM housing_parquet\").df()\n",
    "    result = df[df['housing_median_age'] > 40]\n",
    "    return time.time() - start\n",
    "\n",
    "# 2. Good Query: Filter ‡πÉ‡∏ô Database Engine ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ï‡πà‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ\n",
    "def run_good_query():\n",
    "    start = time.time()\n",
    "    # ‡πÉ‡∏´‡πâ DB Engine Filter ‡πÉ‡∏´‡πâ (Predicate Pushdown) ‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Column ‡πÅ‡∏Ñ‡πà‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ\n",
    "    con.execute(\"\"\"\n",
    "        SELECT median_house_value, housing_median_age \n",
    "        FROM housing_parquet \n",
    "        WHERE housing_median_age > 40\n",
    "    \"\"\").df()\n",
    "    return time.time() - start\n",
    "\n",
    "time_bad = run_bad_query()\n",
    "time_good = run_good_query()\n",
    "\n",
    "print(f\"‚ùå Bad Query Time:  {time_bad:.4f} sec\")\n",
    "print(f\"‚úÖ Good Query Time: {time_good:.4f} sec\")\n",
    "print(f\"üöÄ Speedup: {time_bad/time_good:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682002f4",
   "metadata": {},
   "source": [
    "---\n",
    "## 13) ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏±‡∏ö Apache Spark & Spark SQL\n",
    "\n",
    "### ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏¢‡πâ‡∏≤‡∏¢‡∏à‡∏≤‡∏Å DuckDB ‡πÑ‡∏õ Spark?\n",
    "\n",
    "#### ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á DuckDB (Single-Node Processing)\n",
    "\n",
    "DuckDB ‡πÄ‡∏õ‡πá‡∏ô Engine ‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î:\n",
    "\n",
    "1. **‡∏ñ‡∏π‡∏Å‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏î‡πâ‡∏ß‡∏¢ RAM**: ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤ RAM ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡πÄ‡∏ä‡πà‡∏ô ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 100 GB ‡πÅ‡∏ï‡πà‡∏°‡∏µ RAM ‡πÅ‡∏Ñ‡πà 16 GB) ‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å\n",
    "2. **‡πÉ‡∏ä‡πâ CPU ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß**: ‡πÅ‡∏°‡πâ‡∏à‡∏∞‡∏°‡∏µ Multi-threading ‡πÅ‡∏ï‡πà‡∏Å‡πá‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡πÅ‡∏Ñ‡πà CPU ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡πÄ‡∏ä‡πà‡∏ô 8 cores)\n",
    "3. **‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö Streaming**: DuckDB ‡πÄ‡∏ô‡πâ‡∏ô Batch Processing (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß) ‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö Real-time\n",
    "\n",
    "#### Apache Spark ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?\n",
    "\n",
    "**Apache Spark** ‡πÄ‡∏õ‡πá‡∏ô **Distributed Computing Engine** ‡∏ó‡∏µ‡πà‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠:\n",
    "- ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà (Big Data) ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß\n",
    "- ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÑ‡∏õ‡∏ó‡∏≥‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (Cluster) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô\n",
    "- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Batch Processing ‡πÅ‡∏•‡∏∞ Stream Processing\n",
    "\n",
    "#### ‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô‡∏Ç‡∏≠‡∏á Spark:\n",
    "\n",
    "1. **In-Memory Processing**:\n",
    "   - Spark ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÅ‡∏£‡∏° (RAM) ‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏ô Cluster\n",
    "   - ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤ Hadoop MapReduce (‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏•‡∏á Disk ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á) ‡∏ñ‡∏∂‡∏á **100 ‡πÄ‡∏ó‡πà‡∏≤**\n",
    "\n",
    "2. **Distributed Computing**:\n",
    "   - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ Cluster 100 ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á 16 cores = ‡πÉ‡∏ä‡πâ 1,600 cores ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô\n",
    "   - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 1 TB ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô 100 ‡∏™‡πà‡∏ß‡∏ô ‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏≥ 10 GB\n",
    "\n",
    "3. **Fault Tolerance (‡∏ó‡∏ô‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î)**:\n",
    "   - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏î‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô Cluster ‡∏û‡∏±‡∏á Spark ‡∏à‡∏∞ Re-compute ‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\n",
    "   - ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ **RDD (Resilient Distributed Dataset)** ‡πÅ‡∏•‡∏∞ **DAG (Directed Acyclic Graph)**\n",
    "\n",
    "4. **Lazy Evaluation**:\n",
    "   - Spark ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î\n",
    "   - ‡∏à‡∏∞‡∏£‡∏≠‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏™‡∏±‡πà‡∏á **Action** (‡πÄ‡∏ä‡πà‡∏ô `.show()`, `.count()`) ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏∂‡∏á‡∏ó‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô\n",
    "   - ‡∏ó‡∏≥‡πÉ‡∏´‡πâ Optimize ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ (‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏ß‡∏° Filter ‡∏´‡∏•‡∏≤‡∏¢ ‡πÜ ‡∏ï‡∏±‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)\n",
    "\n",
    "5. **‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤**:\n",
    "   - Python (PySpark)\n",
    "   - Scala (‡∏†‡∏≤‡∏©‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á Spark)\n",
    "   - Java\n",
    "   - R (SparkR)\n",
    "   - **SQL (Spark SQL)** ‚Üê ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏ô‡∏µ‡πâ!\n",
    "\n",
    "### Spark SQL: SQL ‡∏ö‡∏ô Big Data\n",
    "\n",
    "**Spark SQL** ‡∏Ñ‡∏∑‡∏≠ Module ‡∏Ç‡∏≠‡∏á Spark ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ SQL ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Query ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏ô Distributed System\n",
    "\n",
    "#### ‡∏ó‡∏≥‡πÑ‡∏° Spark SQL ‡∏ñ‡∏∂‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç?\n",
    "\n",
    "1. **Syntax ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô SQL ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ**:\n",
    "   - ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô SQL ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÉ‡∏ô DuckDB, PostgreSQL, MySQL\n",
    "   - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏†‡∏≤‡∏©‡∏≤‡πÉ‡∏´‡∏°‡πà (‡πÄ‡∏ä‡πà‡∏ô Scala)\n",
    "\n",
    "2. **‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ö‡∏ô Distributed Data**:\n",
    "   - SQL ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Spark Jobs\n",
    "   - ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏≥‡∏ö‡∏ô‡∏ó‡∏∏‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏ô Cluster\n",
    "\n",
    "3. **Optimize ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥**:\n",
    "   - Spark ‡∏°‡∏µ **Catalyst Optimizer** ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏õ‡∏£‡∏±‡∏ö Query Plan ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡πá‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "   - ‡πÄ‡∏ä‡πà‡∏ô Push-down Filters, Predicate Pushdown, Join Optimization\n",
    "\n",
    "4. **‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢ Data Source**:\n",
    "   - CSV, Parquet, JSON, Avro\n",
    "   - Hive Tables\n",
    "   - JDBC (PostgreSQL, MySQL)\n",
    "   - S3, HDFS, Azure Blob Storage\n",
    "\n",
    "### ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö DuckDB vs Spark SQL\n",
    "\n",
    "| ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ | DuckDB | Spark SQL |\n",
    "|--------|--------|-----------|\n",
    "| **‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•** | MB - GB (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ~100 GB) | GB - PB (‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î) |\n",
    "| **‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á** | 1 ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á | 1 - 1000+ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á |\n",
    "| **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏•‡πá‡∏Å)** | ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å | ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ (Overhead ‡∏à‡∏≤‡∏Å Distribution) |\n",
    "| **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏ç‡πà)** | ‡πÑ‡∏°‡πà‡πÑ‡∏´‡∏ß (Out of Memory) | ‡πÄ‡∏£‡πá‡∏ß (Parallel Processing) |\n",
    "| **Setup** | ‡∏á‡πà‡∏≤‡∏¢ (pip install) | ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Cluster) |\n",
    "| **Use Case** | Data Analysis ‡∏ö‡∏ô Laptop | Production Big Data Pipeline |\n",
    "\n",
    "### Concept: SQL Portability (‡∏¢‡πâ‡∏≤‡∏¢‡πÇ‡∏Ñ‡πâ‡∏î‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢)\n",
    "\n",
    "‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà SQL ‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á:\n",
    "\n",
    "```sql\n",
    "-- SQL ‡∏ô‡∏µ‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á DuckDB ‡πÅ‡∏•‡∏∞ Spark SQL!\n",
    "SELECT \n",
    "    district,\n",
    "    COUNT(*) as total_cases\n",
    "FROM crime\n",
    "WHERE year = 2023\n",
    "GROUP BY district\n",
    "ORDER BY total_cases DESC\n",
    "LIMIT 10\n",
    "```\n",
    "\n",
    "- **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏•‡πá‡∏Å** (1 GB): ‡∏£‡∏±‡∏ô‡∏ö‡∏ô DuckDB ‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á ‚Üí ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡πÉ‡∏ô 2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "- **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏ç‡πà** (1 TB): ‡∏£‡∏±‡∏ô‡∏ö‡∏ô Spark Cluster ‚Üí ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡πÉ‡∏ô 30 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "- **‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô 100%!**\n",
    "\n",
    "### ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° Spark (‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢)\n",
    "\n",
    "![Spark Architecture](images/spark_arch.png)\n",
    "\n",
    "\n",
    "```\n",
    "Driver Program (‡∏Ñ‡∏∏‡∏ì)         Worker Node 1\n",
    "     |                            |\n",
    "     |-- SparkSession             |-- Executor (‡∏ó‡∏≥‡∏á‡∏≤‡∏ô)\n",
    "     |                            |-- Task 1, 2, 3\n",
    "     |                       Worker Node 2\n",
    "     |                            |\n",
    "     |                            |-- Executor\n",
    "     |                            |-- Task 4, 5, 6\n",
    "     |                       Worker Node N...\n",
    "```\n",
    "\n",
    "- **Driver**: ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î (Jupyter Notebook)\n",
    "- **Executor**: ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡∏ö‡∏ô Worker Node ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á\n",
    "- **Task**: ‡∏á‡∏≤‡∏ô‡∏¢‡πà‡∏≠‡∏¢ ‡πÜ ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏•‡∏∞ Executor ‡∏ó‡∏≥\n",
    "\n",
    "### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô\n",
    "\n",
    "‡∏™‡∏°‡∏°‡∏ï‡∏¥‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå `crime.parquet` ‡∏Ç‡∏ô‡∏≤‡∏î 100 GB ‡∏ö‡∏ô S3:\n",
    "\n",
    "1. ‡πÄ‡∏£‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô SQL: `SELECT * FROM crime WHERE year = 2023`\n",
    "2. Spark ‡πÅ‡∏ö‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô 1,000 ‡∏™‡πà‡∏ß‡∏ô (Partitions)\n",
    "3. ‡∏™‡πà‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Partition ‡πÑ‡∏õ‡πÉ‡∏´‡πâ Worker Node ‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡∏ó‡∏≥\n",
    "4. ‡πÅ‡∏ï‡πà‡∏•‡∏∞ Worker Filter ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ `year = 2023` ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á\n",
    "5. ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏ó‡∏µ‡πà Driver\n",
    "6. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•\n",
    "\n",
    "**‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå**: ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ 10 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‚Üí ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 5 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏ö‡∏ô Cluster 100 ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á!\n",
    "\n",
    "### ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ Spark?\n",
    "\n",
    "‚úÖ **‡πÉ‡∏ä‡πâ Spark ‡πÄ‡∏°‡∏∑‡πà‡∏≠**:\n",
    "- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤ RAM ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (> 50-100 GB)\n",
    "- ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö Real-time (Streaming)\n",
    "- ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö Data Lake (S3, HDFS) ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• TB-PB\n",
    "- ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Production Pipeline ‡∏ó‡∏µ‡πà Scalable\n",
    "\n",
    "‚ùå **‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ Spark ‡πÄ‡∏°‡∏∑‡πà‡∏≠**:\n",
    "- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏•‡πá‡∏Å (< 10 GB) ‚Üí ‡πÉ‡∏ä‡πâ DuckDB/Pandas ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤\n",
    "- ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ö‡∏ô Laptop ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß ‚Üí Setup ‡∏¢‡∏∏‡πà‡∏á‡∏¢‡∏≤‡∏Å\n",
    "- ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Prototype ‡πÄ‡∏£‡πá‡∏ß ‡πÜ ‚Üí DuckDB ‡∏á‡πà‡∏≤‡∏¢‡∏Å‡∏ß‡πà‡∏≤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3984a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PySpark (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÉ‡∏ô Colab/Local)\n",
    "# PySpark ‡∏Ñ‡∏∑‡∏≠ Python API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Apache Spark\n",
    "!pip -q install pyspark\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö version\n",
    "import pyspark\n",
    "print(\"PySpark version:\", pyspark.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á SparkSession (‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Spark)\n",
    "# SparkSession ‡∏Ñ‡∏∑‡∏≠ Entry Point ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö Spark\n",
    "# ‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î Local ‡∏à‡∏∞‡πÉ‡∏ä‡πâ CPU ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÄ‡∏≠‡∏á (‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö Cluster ‡∏à‡∏£‡∏¥‡∏á)\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Week3_SparkSQL\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark Session ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!\")\n",
    "print(\"Spark Version:\", spark.version)\n",
    "print(\"Spark UI:\", spark.sparkContext.uiWebUrl)  # ‡∏î‡∏π Monitoring UI (‡∏ñ‡πâ‡∏≤‡∏£‡∏±‡∏ô‡∏ö‡∏ô Local)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d84d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "if os.path.exists(\"housing.parquet\"):\n",
    "    df_spark = spark.read.parquet(\"housing.parquet\")\n",
    "    print(\"‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å Parquet\")\n",
    "else:\n",
    "    df_spark = spark.read.option(\"header\", \"true\").csv(\"sample_data/california_housing_train.csv\")\n",
    "    print(\"‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å CSV\")\n",
    "\n",
    "df_spark.createOrReplaceTempView(\"housing\")\n",
    "df_spark.printSchema()\n",
    "\n",
    "spark_sql = \"\"\"\n",
    "SELECT \n",
    "    housing_median_age,\n",
    "    AVG(median_house_value) as avg_price,\n",
    "    COUNT(*) as count\n",
    "FROM housing\n",
    "GROUP BY housing_median_age\n",
    "ORDER BY avg_price DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "spark.sql(spark_sql).show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
